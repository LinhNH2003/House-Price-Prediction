{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from csv import writer\n",
    "import time\n",
    "import random\n",
    "from lxml import etree as et\n",
    "import urllib.request\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_url = []\n",
    "url = \"https://batdongsan.vn/ban-nha/p\"\n",
    "for i in range(50):\n",
    "    page_url = url + str(i+301+50)\n",
    "    pages_url.append(page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_html(url):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        html = response.read()\n",
    "        html = html.decode('utf-8')\n",
    "    response.close()\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_house_url(soup_page_url):           # link_one_page_no_change\n",
    "    source = download_html(soup_page_url)            #dowload_link_pages_\n",
    "    soup_page_url = BeautifulSoup(source, 'html.parser')\n",
    "    house_url_pages = soup_page_url.find('div',{'class':'datalist'}).findAll('div', {'class':'name'})\n",
    "    for i in range(len(house_url_pages)):\n",
    "        link = house_url_pages[i].find('a')['href']\n",
    "        house_url_pages[i]=link\n",
    "    return house_url_pages                  # link_each_house_on_one_page_co_change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap (location, user, price, infor, title, time):   # title_type_string\n",
    "    \n",
    "    data={}\n",
    "    try:\n",
    "        data['user'] = user.get_text()\n",
    "    except:\n",
    "        data['user'] = None\n",
    "    try: \n",
    "        data['user_link'] = user.find('a')['href']\n",
    "    except:\n",
    "        data['user_link'] = None\n",
    "    data['time'] = time\n",
    "    try: \n",
    "        data['Tinh/TP'] = location[2].get_text()\n",
    "        data['Quan/Huyen'] = location[3].get_text()\n",
    "    except:\n",
    "        data['Tinh/TP'] = None\n",
    "        data['Quan/Huyen'] = None\n",
    "    for i in infor:\n",
    "        data[i.find('strong').text] = None\n",
    "        data[i.find('strong').text] = str(re.search(r'[\\d.]+',i.find(text=True, recursive=False).strip()))\n",
    "        if (i.find('strong').text != 'Diện tích' or i.find('strong').text != 'Phòng ngủ' or i.find('strong').text != 'Phòng WC'):\n",
    "            data[i.find('strong').text] = i.find(text=True, recursive=False).strip()\n",
    "        \n",
    "    data['price'] = None\n",
    "    price = price.contents[0].strip()\n",
    "    if price != 'Thỏa thuận':\n",
    "        price_ = re.match(r'^([\\d.,]+)\\s*(\\D+)$',price)\n",
    "        unit = price_.group(2) \n",
    "        if unit == 'triệu':\n",
    "            data['price'] =  float(price_.group(1)) / 1000\n",
    "        else:\n",
    "            if unit == 'tỷ':\n",
    "                data['price'] =  price_.group(1)\n",
    "    else:\n",
    "        matches = re.findall(r'(\\d+([\\.,]\\d+)?)\\s*(tỷ|tỉ|ty)(\\d{0,3})?', title, re.IGNORECASE)\n",
    "        if matches:\n",
    "            prices = [match[0] for match in matches]\n",
    "            data['price'] = prices[-1]\n",
    "    data['Tầng'] = None\n",
    "    matches = re.findall(r'(\\d+)\\s*(tầng)', title, re.IGNORECASE)\n",
    "    if matches:\n",
    "        floors = [match[0] for match in matches]\n",
    "        data['Tầng'] = floors[0]\n",
    "    else:\n",
    "        matches = re.findall(r'(\\d+)\\s*(lầu)', title, re.IGNORECASE)\n",
    "        if matches:\n",
    "            floors = [match[0] for match in matches]\n",
    "            data['Tầng'] = int(floors[0]) + 1\n",
    "    \n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_house_info(text):\n",
    "    info = {}\n",
    "    info['giá'] = 0\n",
    "    matches = re.findall(r'(\\d+([\\.,]\\d+)*)\\s*(tỷ|tỉ|ty)(\\d{0,3})*', text, re.IGNORECASE)\n",
    "    if matches:\n",
    "        prices = [match[0] for match in matches]\n",
    "        info['giá'] = prices[-1]\n",
    "    if info['giá'] == 0:\n",
    "        matches = re.findall(r'(\\d+([\\.,]\\d+)*)\\s*(tr|trieu|triệu)(\\d{0,3})*', text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            prices = [match[0] for match in matches]\n",
    "            info['giá'] = float(prices[-1]) / 1000\n",
    "    match = re.search(r'((DT:|diện tích:)\\s*[\\d.]+)|([\\d.]\\s*+(m2)+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Diện tích'] = match.group(1)\n",
    "\n",
    "    # Lấy thông tin về số phòng ngủ\n",
    "    match = re.search(r'(\\d+)\\s*(pn|phòng ngủ)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Phòng ngủ'] = str(match.group(1))\n",
    "\n",
    "    # Lấy thông tin về số phòng WC\n",
    "    match = re.search(r'(\\d+)\\s*(wc|phòng vệ sinh)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Phòng WC'] = str(match.group(1))\n",
    "\n",
    "    # Lấy thông tin về số tầng\n",
    "    match = re.search(r'(\\d+)\\s*(tầng)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Số tầng'] = match.group(1)\n",
    "    else:\n",
    "        info['Số tầng'] = 0\n",
    "    # Lấy thông tin về số lầu\n",
    "    match = re.search(r'(\\d+)\\s*(lầu)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Số lầu'] = match.group(1)\n",
    "    else:\n",
    "        info['Số lầu'] = 0\n",
    "    match = re.search(r'(\\d+)\\s*(trệt)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['trệt'] = match.group(1)\n",
    "    else:\n",
    "        info['trệt'] = 0\n",
    "    if info['Số tầng'] == 0:\n",
    "        if info['Số lầu'] == 0 and info['trệt'] != 0 :\n",
    "            info['Số tầng'] = int(info['trệt']) + 1\n",
    "        if info['trệt'] == 0 and info['Số lầu'] != 0:\n",
    "            info['Số tầng'] = int(info['Số lầu']) + 1\n",
    "        if info['trệt'] != 0 and info['Số lầu'] != 0:\n",
    "            info['Số tầng'] = int(info['Số lầu']) + int(info['trệt'])\n",
    "\n",
    "    # Kiểm tra sự có mặt của sân\n",
    "    match = re.search(r'([\\w]+\\s*(sân))|((sân)\\s[\\w]+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Có sân'] = match.group()\n",
    "\n",
    "    match = re.search(r'([\\w\\s]+\\s*(bệnh viện))|((bệnh viện)\\s[\\w\\s]+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Gần bệnh viện'] = match.group()\n",
    "\n",
    "    match = re.search(r'([\\w\\s]+\\s*(chợ|siêu thị))|((chợ|siêu thị)\\s[\\w\\s]+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Gần chợ'] = match.group()\n",
    "\n",
    "    match = re.search(r'([\\w\\s]+\\s*(trường))|((trường)\\s[\\w\\s]+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Gần trường'] = match.group()\n",
    "\n",
    "    match = re.search(r'((dân trí)\\s[\\w\\s]+)|([\\w\\s]+\\s*(dân trí))', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Dân trí'] = match.group()\n",
    "\n",
    "    match = re.search(r'((an ninh)\\s[\\w\\s]+)|([\\w\\s]+\\s*(an ninh))', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['An ninh'] = match.group()\n",
    "\n",
    "    match = re.search(r'([\\w\\s]+\\s*(kinh doanh|buôn bán))|((kinh doanh|buôn bán)\\s[\\w\\s]+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Kinh doanh'] = match.group()\n",
    "\n",
    "    match = re.search(r'((vị trí:|địa điểm:|khu vục:số|đường|quận|huyện|tỉnh|thành phố|tp)[\\s\\w,]+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        info['Địa điểm'] = match.group()\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_libraries(library1, library2):\n",
    "    merged_library = {}\n",
    "\n",
    "    # Gộp thư viện 1\n",
    "    for key, value in library1.items():\n",
    "        merged_library[key] = value\n",
    "\n",
    "    # Gộp thư viện 2\n",
    "    for key, value in library2.items():\n",
    "        merged_library[key] = value\n",
    "\n",
    "    return merged_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_this(link_each_house_pages):            # link_each_house_on_one_page\n",
    "    source_house = download_html(link_each_house_pages) \n",
    "    soup_house = BeautifulSoup(source_house,'html.parser')  # change_link\n",
    "    data1={}\n",
    "    data2={}\n",
    "    data=[]\n",
    "    try:\n",
    "        location = soup_house.find('ul',{'class':'uk-breadcrumb'}).findAll('li')\n",
    "    except:\n",
    "        location=''\n",
    "    try:\n",
    "        user = soup_house.find('div', {'class':'name'})\n",
    "    except:\n",
    "        user=''\n",
    "    try:\n",
    "        price = soup_house.find('strong', class_='price')\n",
    "    except:\n",
    "        price=''\n",
    "    try:\n",
    "        info = soup_house.find('div', {'class':'body'}).findAll('ul',{'class':'uk-list'})\n",
    "    except:\n",
    "        info=''\n",
    "    try:\n",
    "        time = info[1].findAll('li')\n",
    "        info = info[0].findAll('li')\n",
    "    except:\n",
    "        time = info[0]\n",
    "    try:\n",
    "        title = soup_house.find('h1',{'class':'uk-panel-title'}).get_text()\n",
    "    except:\n",
    "        title=''\n",
    "    try:\n",
    "        content = soup_house.find('div',{'class':'content'}).get_text()\n",
    "    except:\n",
    "        content=''\n",
    "  \n",
    "    data1 = scrap(location, user, price, info, title, time)\n",
    "    data2 = extract_house_info(content)\n",
    "    data.append(merge_libraries(data1, data2))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "print(len(pages_url))\n",
    "for i in range(len(pages_url)):                    #link_pages\n",
    "    print(i+301+50)\n",
    "    #input_link_pages_ouput_link_each_house_no_change   \n",
    "    link_house = get_house_url(pages_url[i]) \n",
    "    try: \n",
    "        for j in link_house:     \n",
    "            #input_link_each_house_no_change        \n",
    "            data.extend(scrape_this(j))       \n",
    "            #time.sleep(1)\n",
    "    except:\n",
    "        continue\n",
    "    if i >= 49:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
